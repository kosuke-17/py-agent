import operator
from typing import Annotated, Literal, Sequence, TypedDict
# from langchain_core.utils.function_calling import convert_to_openai_tool_calls
from langchain_core.utils.function_calling import convert_to_openai_tool
from langgraph.graph import START, END, StateGraph
# from langgraph.constants import Send
from openai import OpenAI
from openai.types.chat import ChatCompletionMessageParam

from agent.models import Plan, ReflectionResult, SearchOutput, Subtask
from agent.prompts import ReqDefAgentPrompts
from agent.settings import Settings

class AgentState(TypedDict):
  question: str
  plan: list[str]
  settings: Settings
  current_step: int
  subtask_results: Annotated[Sequence[Subtask], operator.add]
  last_answer: str

class AgentSubGraphState(TypedDict):
  question: str
  plan: list[str]
  subtask: str
  is_completed: bool
  messages: list[ChatCompletionMessageParam]
  challenge_count: int
  # Sequenceã¯é…åˆ—ã‚’æ„å‘³ã™ã‚‹ã®ã§SearchOutputã®2æ¬¡å…ƒé…åˆ—
  # è¤‡æ•°ã®ãƒãƒ¼ãƒ‰ã‹ã‚‰tool_resultsã«å€¤ã‚’è¿½åŠ ã™ã‚‹éš›ã«ã€operator.addã«ã‚ˆã‚Šæ—¢å­˜ã®å€¤ã«çµåˆã•ã‚Œã‚‹
  tool_results: Annotated[Sequence[Sequence[SearchOutput]], operator.add]
  refrection_results: Annotated[Sequence[Sequence[ReflectionResult]], operator.add]
  subtask_answer: str

MAX_CHALLENGE_COUNT = 3

# RequirementsDefinitionAgent
class ReqDefAgent:
  def __init__(
    self,
    settings: Settings,
    tools: list = [],
    prompts: ReqDefAgentPrompts = ReqDefAgentPrompts()
  ) -> None:
    self.settings = settings
    self.tools = tools
    self.tool_map = {tool.name: tool for tool in tools}
    self.prompts = prompts
    self.client = OpenAI(api_key=self.settings.openai_api_key)

  # Pregel: å¤§è¦æ¨¡ã‚°ãƒ©ãƒ•å‡¦ç†ã®ãŸã‚ã®è¨ˆç®—ãƒ¢ãƒ‡ãƒ«
  def create_graph(self):
    workflow = StateGraph(AgentState)

    workflow.add_node("create_plan", self.create_plan)
    # workflow.add_node("execute_subtasks", self.execute_subtasks)
    # workflow.add_node("create_answer", self.create_answer)

    workflow.add_edge(START, "create_plan")
    workflow.add_edge("create_plan", END)
    # workflow.add_conditional_edges("create_plan", self._should_continue_exec_subtasks)
    # workflow.add_edge("execute_subtasks", "create_answer")
    # workflow.set_finish_point("create_answer")

    app = workflow.compile()
    return app

  def create_plan(self, state: AgentState) -> dict:
    """è¨ˆç”»ã‚’ä½œæˆ"""
    print("è¨ˆç”»ã‚’ç”Ÿæˆã™ã‚‹å‡¦ç†ã‚’é–‹å§‹ğŸš€")

    print("OpenAIãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«Toolsã‚’å¤‰æ›")
    # tools = [convert_to_openai_tool_calls(tool) for tool in self.tools]
    tools = []

    system_prompt = self.prompts.planner_system_prompt.format(
      tools=tools
    )
    user_prompt = self.prompts.planner_user_prompt.format(
      question=state["question"]
    )

    messages = [
      {"role": "system", "content": system_prompt},
      {"role": "user", "content": user_prompt},
    ]
    print(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {messages}")

    try:
      response = self.client.beta.chat.completions.parse(
        model=self.settings.openai_model,
        messages=messages,
        response_format=Plan,
        temperature=0,
        seed=0,
      )
    except Exception as e:
      print(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
    
    plan = response.choices[0].message.parsed

    return {"plan": plan.steps}

  def execute_subtasks(self, state: AgentState) -> dict:
    pass

  def create_answer(self, state: AgentState) -> dict:
    pass

  # ç”Ÿæˆã•ã‚ŒãŸè¨ˆç”»æ•°åˆ†ã ã‘ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒå¯èƒ½
  def _should_continue_exec_subtasks(self, state: AgentState) -> list:
    return [
      Send(
        "execute_subtasks",
        {
          "question": state["question"],
          "plan": state["plan"],
          "current_step": idx
        }
      )
      for idx, _ in enumerate(state["plan"])
    ]

  def _create_subgraph(self) -> Pregel:
    """
    ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ

    Returns:
      Pregel: ã‚µãƒ–ã‚°ãƒ©ãƒ•
    """
    workflow = StateGraph(AgentSubGraphState)

    workflow.add_node("select_tools", self.select_tools)
    workflow.add_node("execute_tools", self.execute_tools)
    workflow.add_node("create_subtask_andwer", self.create_subtask_answer)
    workflow.add_node("reflect_subtask", self.reflect_subtask)

    workflow.add_edge(START, "select_tools")
    workflow.add_edge("select_tools", "execute_tools")
    workflow.add_edge("execute_tools", "create_subtask_answer")
    workflow.add_edge("create_subtask_answer", "reflect_subtask")

    workflow.add_conditional_edges(
      "reflect_subtask",
      self._should_continue_exec_subtask_flow,
      {"continue": "select_tools", "end": END}
    )

    app = workflow.complie()
    return app

  def _should_continue_exec_subtask_flow(
      self, state: AgentSubGraphState
    ) -> Literal["end", "continue"]:
    if state["is_completed"] or state["challenge_count"] >= MAX_CHALLENGE_COUNT:
      return "end"
    else:
      return "continue"

  def select_tools(self, state: AgentSubGraphState) -> dict:
    """ãƒ„ãƒ¼ãƒ«ã‚’é¸æŠã™ã‚‹"""
    print("ãƒ„ãƒ¼ãƒ«é¸æŠãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹ğŸš€")
    # OpenAIå¯¾å¿œã®toolå®šç¾©ã«æ›¸ãæ›ãˆã‚‹
    openai_tools = [convert_to_openai_tool(tool) for tool in self.tools]

    # ãƒªãƒˆãƒ©ã‚¤ã•ã‚ŒãŸã‹ã©ã†ã‹ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰ãˆã‚‹
    if state["challenge_count"] == 0:
      print("toolæ´—æ¿¯ã®ãŸã‚ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆä¸­...")
      user_prompt = self.prompts.subtask_tool_selection_user_prompt.format(
        question=state["question"],
        plan=state["plan"],
        subtask=state["subtask"],
      )
      messages = [
        { "role": "system", "content": self.prompts.subtask_system_prompt },
        { "role": "user", "content": user_prompt}
      ]
    else:
      print("ãƒªãƒˆãƒ©ã‚¤ãƒ„ãƒ¼ãƒ«ä½œæˆç”¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆä¸­...")

      messages: list = state["messages"]
      messages = [
        message
        for message in messages
        if message["role"] != "tool" or "tool_calls" not in message
      ]
      user_retry_prompt = self.prompts.subtask_retry_answer_user_prompt
      user_message = {"role": "user", "content": user_retry_prompt}
      messages.append(user_message)

      try:
        print("OpenAIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ä¸­...")
        response = self.client.chat.completions.create(
          model=self.settings.openai_model,
          messages=messages,
          tools=openai_tools,
          temperature=0,
          seed=0
        )
        print("æˆåŠŸâœ…")
      except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ:{e}")
        raise

      if response.choices[0].message.tool_calls is None:
        raise ValueError("Tool CallsãŒã‚ã‚Šã¾ã›ã‚“")

      ai_message = {
        "role": "assistant",
        "tool_calls": [
          tool_call.model_dump()
          for tool_call in response.choices[0].message.tool_calls
        ]
      }
      print("ãƒ„ãƒ¼ãƒ«é¸æŠçµ‚äº†!")
      messages.append(ai_message)
      # ãƒªãƒˆãƒ©ã‚¤ã®å ´åˆã¯è¿½åŠ åˆ†ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ã‚’æ›´æ–°
      return {"messages": messages}
